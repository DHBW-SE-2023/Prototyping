{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24744c05b666c83"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pytesseract\n",
    "import re\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = \"C:/Program Files/Tesseract-OCR/tesseract.exe\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T08:23:48.749177800Z",
     "start_time": "2023-10-27T08:23:48.742087500Z"
    }
   },
   "id": "6647bde1faafeb4c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Opening the image"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b74cfeea3575c0a"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "image = cv2.imread(\"./img/list_3.jpg\")\n",
    "\n",
    "def blur_and_threshold(gray):\n",
    "    gray = cv2.GaussianBlur(gray, (3, 3), 2)\n",
    "    threshold = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "    threshold = cv2.fastNlMeansDenoising(threshold, 11, 31, 9)\n",
    "    return threshold\n",
    "\n",
    "\n",
    "# ## **Find the Biggest Contour**\n",
    "\n",
    "# **Note: We made sure the minimum contour is bigger than 1/10 size of the whole picture. This helps in removing very small contours (noise) from our dataset**\n",
    "\n",
    "\n",
    "def biggest_contour(contours, min_area):\n",
    "    biggest = None\n",
    "    max_area = 0\n",
    "    biggest_n = 0\n",
    "    approx_contour = None\n",
    "    for n, i in enumerate(contours):\n",
    "        area = cv2.contourArea(i)\n",
    "\n",
    "        if area > min_area / 10:\n",
    "            peri = cv2.arcLength(i, True)\n",
    "            approx = cv2.approxPolyDP(i, 0.02 * peri, True)\n",
    "            if area > max_area and len(approx) == 4:\n",
    "                biggest = approx\n",
    "                max_area = area\n",
    "                biggest_n = n\n",
    "                approx_contour = approx\n",
    "\n",
    "    return biggest_n, approx_contour\n",
    "\n",
    "\n",
    "def order_points(pts):\n",
    "    # initialzie a list of coordinates that will be ordered\n",
    "    # such that the first entry in the list is the top-left,\n",
    "    # the second entry is the top-right, the third is the\n",
    "    # bottom-right, and the fourth is the bottom-left\n",
    "    pts = pts.reshape(4, 2)\n",
    "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "\n",
    "    # the top-left point will have the smallest sum, whereas\n",
    "    # the bottom-right point will have the largest sum\n",
    "    s = pts.sum(axis=1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "\n",
    "    # now, compute the difference between the points, the\n",
    "    # top-right point will have the smallest difference,\n",
    "    # whereas the bottom-left will have the largest difference\n",
    "    diff = np.diff(pts, axis=1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "\n",
    "    # return the ordered coordinates\n",
    "    return rect\n",
    "\n",
    "\n",
    "# ## Find the exact (x,y) coordinates of the biggest contour and crop it out\n",
    "\n",
    "\n",
    "def four_point_transform(image, pts):\n",
    "    # obtain a consistent order of the points and unpack them\n",
    "    # individually\n",
    "    rect = order_points(pts)\n",
    "    (tl, tr, br, bl) = rect\n",
    "\n",
    "    # compute the width of the new image, which will be the\n",
    "    # maximum distance between bottom-right and bottom-left\n",
    "    # x-coordiates or the top-right and top-left x-coordinates\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "    # compute the height of the new image, which will be the\n",
    "    # maximum distance between the top-right and bottom-right\n",
    "    # y-coordinates or the top-left and bottom-left y-coordinates\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "\n",
    "    # now that we have the dimensions of the new image, construct\n",
    "    # the set of destination points to obtain a \"birds eye view\",\n",
    "    # (i.e. top-down view) of the image, again specifying points\n",
    "    # in the top-left, top-right, bottom-right, and bottom-left\n",
    "    # order\n",
    "    dst = np.array([\n",
    "        [0, 0],\n",
    "        [maxWidth - 1, 0],\n",
    "        [maxWidth - 1, maxHeight - 1],\n",
    "        [0, maxHeight - 1]], dtype=\"float32\")\n",
    "\n",
    "    # compute the perspective transform matrix and then apply it\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "\n",
    "    # return the warped image\n",
    "    return warped\n",
    "\n",
    "\n",
    "# # Transformation the image\n",
    "\n",
    "# **1. Convert the image to grayscale**\n",
    "\n",
    "# **2. Remove noise and smoothen out the image by applying blurring and thresholding techniques**\n",
    "\n",
    "# **3. Use Canny Edge Detection to find the edges**\n",
    "\n",
    "# **4. Find the biggest contour and crop it out**\n",
    "\n",
    "\n",
    "def transformation(image):\n",
    "    image = image.copy()\n",
    "\n",
    "    height, width, channels = image.shape\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image_size = gray.size\n",
    "\n",
    "    threshold = blur_and_threshold(gray)\n",
    "    # We need two threshold values, minVal and maxVal. Any edges with intensity gradient more than maxVal\n",
    "    # are sure to be edges and those below minVal are sure to be non-edges, so discarded.\n",
    "    #  Those who lie between these two thresholds are classified edges or non-edges based on their connectivity.\n",
    "    # If they are connected to \"sure-edge\" pixels, they are considered to be part of edges.\n",
    "    #  Otherwise, they are also discarded\n",
    "    edges = cv2.Canny(threshold, 50, 150, apertureSize=7)\n",
    "    contours, hierarchy = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    simplified_contours = []\n",
    "\n",
    "    for cnt in contours:\n",
    "        hull = cv2.convexHull(cnt)\n",
    "        poly = cv2.approxPolyDP(hull, 0.001 * cv2.arcLength(hull, True), True)\n",
    "        if poly.shape[0] != 4:\n",
    "            continue\n",
    "        simplified_contours.append(poly)\n",
    "    simplified_contours = np.array(simplified_contours)\n",
    "    biggest_n, approx_contour = biggest_contour(simplified_contours, image_size)\n",
    " \n",
    "    threshold = cv2.drawContours(image, simplified_contours, -1, (0, 0, 0), 1)\n",
    "    \n",
    "    dst = 0\n",
    "    if approx_contour is not None and len(approx_contour) == 4:\n",
    "        approx_contour = np.float32(approx_contour)\n",
    "        dst = four_point_transform(threshold, approx_contour)\n",
    "    croppedImage = dst\n",
    "    return croppedImage\n",
    "\n",
    "\n",
    "# **Increase the brightness of the image by playing with the \"V\" value (from HSV)**\n",
    "\n",
    "def increase_brightness(img, value=30):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    h, s, v = cv2.split(hsv)\n",
    "    lim = 255 - value\n",
    "    v[v > lim] = 255\n",
    "    v[v <= lim] += value\n",
    "    final_hsv = cv2.merge((h, s, v))\n",
    "    img = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n",
    "    return img\n",
    "\n",
    "\n",
    "# **Sharpen the image using Kernel Sharpening Technique**\n",
    "\n",
    "\n",
    "def final_image(rotated):\n",
    "    # Create our shapening kernel, it must equal to one eventually\n",
    "    kernel_sharpening = np.array([[0, -1, 0],\n",
    "                                  [-1, 5, -1],\n",
    "                                  [0, -1, 0]])\n",
    "    # applying the sharpening kernel to the input image & displaying it.\n",
    "    sharpened = cv2.filter2D(rotated, -1, kernel_sharpening)\n",
    "    sharpened = increase_brightness(sharpened, 30)\n",
    "    return sharpened\n",
    "\n",
    "blurred_threshold = transformation(image)\n",
    "image = final_image(blurred_threshold)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T08:23:56.561639400Z",
     "start_time": "2023-10-27T08:23:49.207059200Z"
    }
   },
   "id": "2115fd51096a1f2e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Paper sheet detection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b3b2599f04afb4c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Reverse perspective transform"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9625e1b38794271a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Table detection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47341f8e6363e2e6"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "['Intelligente Systeme TIK',\n '',\n 'Baumann, Lysann',\n 'Beetz, Robin Georg',\n 'Beuerle, Marco',\n 'Domitrovic, Max',\n 'Druica, Mathias',\n 'Egger, Julia',\n 'Fischer, David',\n 'Fisher, Jamie',\n 'Gmeiner, Leander Gabriel Mauritius',\n 'Handschuh, Jannik ',\n 'Hogan, Finley ',\n 'Kiele, Milan',\n 'Marschall, Linus',\n 'Medwedkin, Eduard',\n 'Naas, Jasper',\n 'Nusch, Hannes',\n 'Rottweiler, Philipp',\n 'Schilling, Tobias',\n 'Schneider, AnnaSophie',\n 'Seidel, Yannick',\n 'Siegert, Daniel Valentin',\n 'Zagst, Jonas',\n '',\n '']"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denoised = cv2.fastNlMeansDenoising(image, None, 10) # TODO Parameter\n",
    "\n",
    "gray = cv2.cvtColor(denoised, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# gray_blurred = cv2.GaussianBlur(gray, (0,0), 3)\n",
    "# gray = cv2.addWeighted(gray, 1.5, gray_blurred, -0.5, 0)\n",
    "\n",
    "_, binary = cv2.threshold(gray, 128, 255, cv2.THRESH_OTSU)\n",
    "binary = 255 - binary\n",
    "\n",
    "vertical_kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(1, binary.shape[1] // 150))\n",
    "\n",
    "binary_vertical = cv2.erode(binary, vertical_kernel, iterations=7)\n",
    "binary_vertical = cv2.dilate(binary_vertical, vertical_kernel, iterations=7)\n",
    "\n",
    "\n",
    "horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(binary.shape[1] // 150, 1))\n",
    "\n",
    "binary_horizontal = cv2.erode(binary, horizontal_kernel, iterations=7)\n",
    "binary_horizontal = cv2.dilate(binary_horizontal, horizontal_kernel, iterations=7)\n",
    "\n",
    "vh_lines = cv2.addWeighted(binary_vertical, 0.5, binary_horizontal, 0.5, 0)\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n",
    "vh_lines = cv2.erode(~vh_lines, kernel, iterations=3)\n",
    "\n",
    "_, vh_lines = cv2.threshold(vh_lines, 128, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY)\n",
    "# vh_lines = cv2.cvtColor(vh_lines, cv2.COLOR_GRAY2RGB)\n",
    "# image_vh_lines = cv2.bitwise_not(cv2.bitwise_xor(image, vh_lines))\n",
    "\n",
    "# Finding contours\n",
    "\n",
    "contours, hierachy = cv2.findContours(vh_lines, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "bounding_boxes = [cv2.boundingRect(c) for c in contours]\n",
    "(contours, bounding_boxes) = zip(*sorted(zip(contours, bounding_boxes),key=lambda x:x[1][1]))\n",
    "\n",
    "boxes: list[list[int]] = []\n",
    "for contour in contours:\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    # image_vh_lines = cv2.rectangle(image_vh_lines, (x,y), (x+w,y+h), (0, 255, 0), 2)\n",
    "    boxes.append([x,y,w,h])\n",
    "\n",
    "\n",
    "columns = []\n",
    "rows = []\n",
    "\n",
    "mean_height = np.mean([box[3] for box in boxes])\n",
    "columns.append(boxes[0])\n",
    "previous = boxes[0]\n",
    "for box in boxes:\n",
    "    if box[1] <= (previous[1] + mean_height / 2):\n",
    "        columns.append(box)\n",
    "        previous = box\n",
    "        if box is boxes[-1]:\n",
    "            rows.append(columns)\n",
    "    else:\n",
    "        rows.append(columns)\n",
    "        columns = []\n",
    "        previous = box\n",
    "        columns.append(box)\n",
    "else:\n",
    "    rows.append(columns)\n",
    "    \n",
    "for idx, row in enumerate(rows):\n",
    "    rows[idx] = list(sorted(row, key=lambda r: r[0]))\n",
    "\n",
    "# image_2 = image.copy()\n",
    "\n",
    "names = []\n",
    "delta = 1\n",
    "\n",
    "min_x = rows[0][1][0] - 10\n",
    "\n",
    "for idx, row in enumerate(rows):    \n",
    "    if len(row) < 2:\n",
    "        continue\n",
    "        \n",
    "    x, y, w, h = row[1]    \n",
    "    name_column = binary[y+delta:y+h-delta, x+delta:x+w-delta]\n",
    "    \n",
    "        \n",
    "    if x < min_x:\n",
    "        rows[idx] = row[1:]\n",
    "        x, y, w, h = rows[idx][1] \n",
    "        name_column = binary[y+delta:y+h-delta, x+delta:x+w-delta]\n",
    "    \n",
    "    scaling = 2\n",
    "    new_shape = (int(name_column.shape[1] * scaling), int(name_column.shape[0] * scaling))\n",
    "    name_column = cv2.resize(name_column, new_shape)\n",
    "    name_column = cv2.morphologyEx(name_column, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_CROSS, (3,3)), iterations=1)\n",
    "    _, name_column = cv2.threshold(name_column, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    w, h = name_column.shape\n",
    "    d = delta * 2\n",
    "    \n",
    "    name_column = name_column[d:w-d, d:h-d]\n",
    "\n",
    "    if name_column.size == 0:\n",
    "        continue    \n",
    "        \n",
    "    \"\"\"\n",
    "    scaling = 10\n",
    "    new_shape = (int(name_column.shape[1] * scaling), int(name_column.shape[0] * scaling))\n",
    "    name_column = cv2.resize(name_column, new_shape)\n",
    "    \n",
    "    name_column = cv2.fastNlMeansDenoising(name_column, None, 10)\n",
    "    \n",
    "    name_column = cv2.morphologyEx(name_column, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_RECT, (3,3)), iterations=1)\n",
    "    name_blurred = cv2.GaussianBlur(name_column, (0,0), 3)\n",
    "    name_column = cv2.addWeighted(name_column, -0.5, name_blurred, 1.5, 0)\n",
    "\n",
    "    _, name_column = cv2.threshold(name_column, 128, 255, cv2.THRESH_OTSU)\n",
    "    \"\"\"\n",
    "    name_column = 255 - name_column\n",
    "    \n",
    "    # cv2.imwrite(\"./img/output.png\", name_column)\n",
    "    \n",
    "    name = pytesseract.image_to_string(name_column, lang=\"eng\")\n",
    "    name = name.strip()\n",
    "    regex = re.compile('[^a-zA-Z ,]')\n",
    "    name = regex.sub(\"\", name)\n",
    "    names.append(name)\n",
    "    \n",
    "names\n",
    "    \n",
    "# cv2.imwrite(\"./img/output.png\", gray)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T08:31:20.298728Z",
     "start_time": "2023-10-27T08:31:03.078721800Z"
    }
   },
   "id": "6195ad97cfd4c4f0"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Baumann, Lysann': True, 'Beetz, Robin Georg': False, 'Beuerle, Marco': False, 'Domitrovic, Max': False, 'Druica, Mathias': True, 'Egger, Julia': True, 'Fischer, David': True, 'Fisher, Jamie': True, 'Gmeiner, Leander Gabriel Mauritius': True, 'Handschuh, Jannik ': False, 'Hogan, Finley ': True, 'Kiele, Milan': True, 'Marschall, Linus': True, 'Medwedkin, Eduard': True, 'Naas, Jasper': True, 'Nusch, Hannes': True, 'Rottweiler, Philipp': True, 'Schilling, Tobias': True, 'Schneider, AnnaSophie': False, 'Seidel, Yannick': True, 'Siegert, Daniel Valentin': True, 'Zagst, Jonas': True}\n"
     ]
    }
   ],
   "source": [
    "o_img = binary - (255 - vh_lines)\n",
    "names_signatures = list(filter(lambda x: x[0] and len(x[1]) > 2, zip(names, rows)))\n",
    "\n",
    "mean_height = np.mean([row[2][3] for _, row in names_signatures])\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (18, 7))\n",
    "\n",
    "o_img = cv2.cvtColor(o_img, cv2.COLOR_GRAY2RGB)\n",
    "o_img_c= o_img.copy()\n",
    "\n",
    "results: dict[str, bool] = {}\n",
    "for name, row in names_signatures[1:]:\n",
    "    x, y, w, h = row[2]\n",
    "    # h += int(mean_height) // 3\n",
    "    # y -= int(mean_height) // 6\n",
    "    \n",
    "    # o_img = o_img[y:y+h, x:x+w]\n",
    "    \n",
    "    # o_img = cv2.adaptiveThreshold(o_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "    # o_img = cv2.fastNlMeansDenoising(o_img, None, 180)\n",
    "    o_img_sec = cv2.Canny(o_img[y:y+h, x:x+w], 128, 255)\n",
    "    \n",
    "    o_img_sec = cv2.morphologyEx(o_img_sec, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "    \n",
    "    cnts, hier = cv2.findContours(o_img_sec, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE, offset=(x,y))\n",
    "    \n",
    "    filtered_cnts = []\n",
    "    for contour in cnts:\n",
    "        cx, cy, cw, ch = cv2.boundingRect(contour)\n",
    "        \n",
    "        # o_img_c = cv2.rectangle(o_img_c, (cx,cy), (cx+cw,cy+ch), (0, 255, 0), 1)\n",
    "        if cw < w // 15 or ch < h // 2:\n",
    "            continue\n",
    "        \n",
    "        o_img_c = cv2.rectangle(o_img_c, (cx,cy), (cx+cw,cy+ch), (0, 255, 0), 1)\n",
    "        # o_img = cv2.drawContours(o_img_c, [contour], 0, (255, 255, 0), -1)\n",
    "        filtered_cnts.append(contour)\n",
    "        \n",
    "    results[name] = len(filtered_cnts) == 1\n",
    "        \n",
    "    x, y, w, h = row[2]\n",
    "    \n",
    "    if results[name]:\n",
    "        cv2.rectangle(o_img_c, (x,y), (x+w,y+h), (0, 255, 0), 2)\n",
    "    else:\n",
    "        cv2.rectangle(o_img_c, (x,y), (x+w,y+h), (0, 0, 255), 2)\n",
    "    \n",
    "# o_img = cv2.rectangle(o_img, (min_x, min_y), (max_x, max_y), 255, 2)\n",
    "cv2.imwrite(\"./img/output.png\", o_img_c)\n",
    "print(results)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T08:34:11.289894700Z",
     "start_time": "2023-10-27T08:34:11.077164700Z"
    }
   },
   "id": "c59301709df1c1f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "image = cv2.imread(\"./img/list_2.jpg\")\n",
    "\n",
    "hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "lower = np.array([90, 38, 0])\n",
    "upper = np.array([145, 255, 255])\n",
    "mask = cv2.inRange(hsv, lower, upper)\n",
    "result = cv2.bitwise_and(image, image, mask=mask)\n",
    "result[mask==0] = (255, 255, 255)\n",
    "\n",
    "cv2.imwrite(\"./img/output.png\", result)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61d4436f0cd09adb"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "[('Intelligente Systeme TIK22',\n  [[8, 10, 104, 403],\n   [120, 8, 1247, 412],\n   [1375, 4, 1103, 415],\n   [1375, 4, 1103, 415]]),\n ('Baumann, Lysann',\n  [[9, 422, 104, 59],\n   [122, 423, 1244, 64],\n   [1375, 422, 1101, 65],\n   [2485, 425, 1, 58]]),\n ('Beetz, Robin Georg',\n  [[10, 489, 103, 59],\n   [122, 491, 1244, 63],\n   [1375, 489, 1101, 66],\n   [2485, 492, 1, 58]]),\n ('Beuerle, Marco',\n  [[10, 557, 103, 59],\n   [122, 558, 1244, 64],\n   [1374, 557, 1101, 66],\n   [2484, 560, 2, 58]]),\n ('Domitrovic, Max',\n  [[10, 625, 104, 59],\n   [123, 626, 1242, 64],\n   [1374, 625, 1102, 65],\n   [2485, 627, 1, 58]]),\n ('Druica, Mathias',\n  [[11, 693, 103, 58],\n   [123, 693, 1243, 64],\n   [1375, 693, 1101, 65],\n   [2485, 694, 1, 59]]),\n ('Egger, Julia',\n  [[11, 760, 103, 59],\n   [123, 761, 1242, 64],\n   [1375, 760, 1101, 66],\n   [2485, 762, 1, 39]]),\n ('Fischer, David',\n  [[11, 828, 103, 58], [123, 828, 1242, 64], [1374, 828, 1103, 65]]),\n ('Fisher, Jamie',\n  [[11, 895, 103, 58], [123, 896, 1243, 63], [1374, 895, 1103, 65]]),\n ('Gmeiner, Leander Gabriel Mauritius',\n  [[10, 962, 104, 58], [123, 963, 1242, 63], [1374, 962, 1104, 64]]),\n ('Handschuh, Jannik',\n  [[11, 1029, 103, 58], [123, 1029, 1242, 64], [1374, 1028, 1104, 65]]),\n ('Hogan, Finley',\n  [[11, 1097, 103, 58], [123, 1096, 1242, 64], [1374, 1095, 1104, 65]]),\n ('Kiele, Milan',\n  [[11, 1164, 103, 59], [123, 1164, 1242, 63], [1374, 1163, 1104, 64]]),\n ('Marschall, Linus',\n  [[12, 1232, 102, 59], [123, 1232, 1242, 62], [1374, 1231, 1104, 64]]),\n ('Medwedkin, Eduard',\n  [[12, 1300, 102, 59], [124, 1300, 1241, 61], [1374, 1299, 1103, 62]]),\n ('Naas, Jasper',\n  [[12, 1367, 102, 59], [123, 1367, 1242, 61], [1374, 1367, 1103, 62]]),\n ('Nusch, Hannes',\n  [[11, 1435, 103, 59], [123, 1435, 1242, 60], [1374, 1435, 1102, 60]]),\n ('Rottweiler, Philipp',\n  [[11, 1503, 104, 58], [124, 1502, 1241, 59], [1374, 1502, 1102, 60]]),\n ('Schilling, Tobias',\n  [[11, 1570, 103, 59], [123, 1570, 1242, 59], [1374, 1570, 1103, 59]]),\n ('Schneider, Anna-Sophie',\n  [[11, 1638, 103, 58], [123, 1636, 1242, 60], [1375, 1637, 1102, 59]]),\n ('Seidel, Yannick',\n  [[11, 1705, 103, 59], [123, 1703, 1243, 61], [1375, 1703, 1103, 61]]),\n ('Siegert, Daniel Valentin',\n  [[11, 1773, 103, 59], [123, 1770, 1243, 62], [1375, 1771, 1103, 61]]),\n ('Zagst, Jonas',\n  [[11, 1841, 103, 59], [123, 1838, 1243, 62], [1375, 1838, 1103, 61]])]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_signatures"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T07:49:25.213130900Z",
     "start_time": "2023-10-27T07:49:25.200495200Z"
    }
   },
   "id": "4fa288bb573ffcd4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Row/Column detection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d2c955728134b2c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Printed text detection (left column)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c8e6d51dbe2a3f6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Detection of valid signature fields"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "162a68a1f8a127b4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extraction of list of user and if valid signature is present"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2417c0c9065ac9d9"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T07:49:25.231272900Z",
     "start_time": "2023-10-27T07:49:25.219038100Z"
    }
   },
   "id": "47f0dbdd0115f2dd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
